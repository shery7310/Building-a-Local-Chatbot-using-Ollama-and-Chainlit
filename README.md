# Building-a-Local-Chatbot-using-Ollama-and-Chainlit
This repo aims to help you run your own chatbot if you are running an ollama server, the basic chatbot can retain memory and will run in your browser. The repo also helps you setup ollama Modelfiles and understand and use parameters to increase/decrease layer offloading/context window etc. It's very easy to get your own chatbot running locally.
